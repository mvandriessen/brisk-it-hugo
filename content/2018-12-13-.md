---
title: Using Veeam Quick Migration to move multi-writer vmdk
author: Maarten Van Driessen
type: post
date: -001-11-30T00:00:00+00:00
draft: true
url: /?p=199
categories:
  - Uncategorized

---
<<Instert intro here >>

There are some pre-requisites you need to check before setting the flag

  * VMDK had to be thick provisioned eager zeroed
  * CBT has to be disabled on the VMDK
  * You can't put the VMDK on the same SCSI controller as the OS disk
  * VMDK should be independent - persistent

**PREREQS NOG DUBBEL CHECKEN**

# Setting up the test VM

To try out the move before actually doing it, I went ahead and created 2 new virtual machines and deployed Windows Server to them. After the deployment completed, I created a new, thick provisioned eager zeroed, virtual disk and added it to the first VM, on a separate controller.

The next step is to set the multi-writer flag. Before vSphere 6.0 U1, this was done using an advanced setting (SCSI1:0.sharing = "multi-writer"). Since then, you can do it using the Web/H5 client as shown below.

[<img loading="lazy" class="aligncenter size-full wp-image-200" src="https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/new-disk.png?resize=612%2C404" alt="" width="612" height="404" srcset="https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/new-disk.png?w=612&ssl=1 612w, https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/new-disk.png?resize=300%2C198&ssl=1 300w" sizes="(max-width: 612px) 100vw, 612px" data-recalc-dims="1" />][1]

On the second VM, perform the same steps but add an existing disk instead of creating a new one. To keep things simple, I highly recommend that you use the same Virtual Device Node for both VMs.

Disabling CBT is the only thing left before we can power on the VM. This is still done using advanced settings on the VM. Unfortunately, today this is not possible yet in the H5 client. Open the VM settings and go to the advanced settings. Add the parameter as shown below. Do this for every shared disk you added to the VMs.[<img loading="lazy" class="aligncenter size-full wp-image-202" src="https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/disable-CBT.png?resize=703%2C516" alt="" width="703" height="516" srcset="https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/disable-CBT.png?w=703&ssl=1 703w, https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/disable-CBT.png?resize=300%2C220&ssl=1 300w" sizes="(max-width: 703px) 100vw, 703px" data-recalc-dims="1" />][2]

You should now be able to power on both VMs at the same time. You can do some tests now or put some data on the disks, so you're sure everything is working fine. When you're satisfied everything works as expected, shut both VMs down.

# Preparing the VMs for migration

In order for the migration to produce the expected results, you have to remove the shared disks from one VM. If you leave them attached, Veeam will detect them on each VM and perform the migration of these disks for each VM. This leaves you with double disks on the destination side.

The settings you just configured should stay in the configuration file.

# Performing the migration

 [1]: https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/new-disk.png
 [2]: https://i0.wp.com/www.brisk-it.net/wp-content/uploads/2017/08/disable-CBT.png